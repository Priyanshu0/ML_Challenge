{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy tensorflow matplotlib tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ssl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.nn import softmax, log_softmax\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing whether tensorflow will use GPU or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "GPU details:  {'device_name': 'METAL'}\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.list_physical_devices()\n",
    "print(\"\\nDevices: \", devices)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  details = tf.config.experimental.get_device_details(gpus[0])\n",
    "  print(\"GPU details: \", details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['klimb_llm_optimization_challenge',\n",
       " '.DS_Store',\n",
       " 'ML_Challenge.code-workspace',\n",
       " 'Challenge.ipynb',\n",
       " '.venv',\n",
       " 'teacher_model.pkl',\n",
       " 'tmp']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of train and test data\n",
    "train_dir = \"./klimb_llm_optimization_challenge/seg_train/\"\n",
    "test_dir = \"./klimb_llm_optimization_challenge/seg_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data configs\n",
    "batch_size = 32\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "seed = 123\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Train and Test Set from the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 files belonging to 6 classes.\n",
      "Using 11228 files for training.\n",
      "Using 2806 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 01:01:48.456726: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2024-02-09 01:01:48.456744: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-02-09 01:01:48.456752: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-02-09 01:01:48.456786: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-02-09 01:01:48.457034: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "train_dir,\n",
    "  validation_split=validation_split,\n",
    "  subset=\"both\",\n",
    "  seed=seed,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_dir,\n",
    "  seed=seed,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(images, labels):\n",
    "    # Preprocess images using preprocess_input\n",
    "    images = preprocess_input(images)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_train_ds = train_ds.map(preprocess_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_test_ds = test_ds.map(preprocess_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_val_ds = val_ds.map(preprocess_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the MASTER Model - using Transfer Learning\n",
    "# Here we are using ImageNet pre-trained model weights\n",
    "base_model = keras.applications.ResNet152(\n",
    "\t\tweights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "\t\tinput_shape=(img_height, img_width, 3),\n",
    "\t\tinclude_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(img_height, img_width, 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning.\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(num_classes)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch < 5:\n",
    "    return lr\n",
    "  else:\n",
    "    return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './tmp/checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " resnet152 (Functional)      (None, 5, 5, 2048)        58370944  \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 2048)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 12294     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58383238 (222.71 MB)\n",
      "Trainable params: 12294 (48.02 KB)\n",
      "Non-trainable params: 58370944 (222.67 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(\n",
    "\t\toptimizer=keras.optimizers.legacy.Adam(learning_rate=lr),\n",
    "\t\tloss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "\t\tmetrics=[keras.metrics.SparseCategoricalAccuracy()], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_epochs = 20\n",
    "# history = model.fit(preprocess_train_ds, epochs=train_epochs, callbacks=[scheduler_callback, checkpoint_callback, earlystopping_callback], verbose=1, validation_data=preprocess_val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"./teacher_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 01:01:52.929176: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open ./teacher_model.pkl/: FAILED_PRECONDITION: teacher_model.pkl; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2837e1d20>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"./teacher_model.pkl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 01:01:54.279684: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 38s 413ms/step\n"
     ]
    }
   ],
   "source": [
    "val_labels = model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 37s 397ms/step\n"
     ]
    }
   ],
   "source": [
    "test_labels = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 39s 391ms/step - loss: 0.5907 - sparse_categorical_accuracy: 0.7997\n"
     ]
    }
   ],
   "source": [
    "test_reults = model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 153s 436ms/step\n"
     ]
    }
   ],
   "source": [
    "train_labels = model.predict(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_student_model(input_shape, num_classes):\n",
    "  model = keras.models.Sequential()\n",
    "  model.add(layers.Conv2DTranspose(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape, strides=(1,1)))\n",
    "  model.add(layers.MaxPooling2D((2, 2), padding='valid', strides=(1,1)))\n",
    "  model.add(layers.Conv2D(64, kernel_size= (5, 5), activation='relu', strides=(1,1)))\n",
    "  model.add(layers.MaxPooling2D((4,4), padding='valid', strides=(1,1)))\n",
    "  model.add(layers.GlobalAveragePooling2D())\n",
    "  model.add(layers.Dense(num_classes))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = create_student_model((img_height, img_width, 3), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_transpose_3 (Conv2D  (None, 152, 152, 32)      896       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 151, 151, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 147, 147, 64)      51264     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 144, 144, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_4  (None, 64)                0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52550 (205.27 KB)\n",
      "Trainable params: 52550 (205.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "student_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 7.0\n",
    "alpha = 0.3\n",
    "num_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_student_model(teacher_model, student_model, train_ds, val_ds, num_epochs=50, learning_rate=lr):\n",
    "  optimizer=keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
    "  criterian_distillation = keras.losses.KLDivergence()\n",
    "  criterian = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "  accuracy_fn = keras.metrics.SparseCategoricalAccuracy()\n",
    "  train_epoch_loss = np.array([])\n",
    "  train_epoch_accuracy = np.array([])\n",
    "\n",
    "  val_epoch_loss = np.array([])\n",
    "  val_epoch_accuracy = np.array([])\n",
    "  for epoch in range(num_epochs):\n",
    "    train_batch_loss = np.array([])\n",
    "    train_batch_accuracy = np.array([])\n",
    "\n",
    "    val_batch_loss = np.array([])\n",
    "    val_batch_accuracy = np.array([])\n",
    "\n",
    "    for batch_inputs, batch_labels in tqdm(train_ds):\n",
    "\n",
    "      with tf.GradientTape() as tape:\n",
    "\n",
    "        student_logits = student_model(batch_inputs, training=True)\n",
    "        teacher_logits = teacher_model(batch_inputs, training=False)\n",
    "\n",
    "\n",
    "        distillation_loss = criterian_distillation(log_softmax(teacher_logits / T, axis=-1), softmax(student_logits / T, axis=-1))\n",
    "\n",
    "        hard_target_loss = criterian(batch_labels, student_logits)\n",
    "\n",
    "        loss = alpha * hard_target_loss + (1.0 - alpha) * T ** 2 * distillation_loss\n",
    "\n",
    "        accuracy_fn.update_state(y_true=batch_labels, y_pred=student_logits)\n",
    "        train_batch_loss = np.append(train_batch_loss, loss.numpy())\n",
    "        train_batch_accuracy = np.append(train_batch_accuracy, accuracy_fn.result().numpy())\n",
    "\n",
    "      grads = tape.gradient(loss, student_model.trainable_variables)\n",
    "      optimizer.apply_gradients(zip(grads, student_model.trainable_variables))\n",
    "\n",
    "    train_epoch_accuracy = np.append(train_epoch_accuracy, train_batch_accuracy.mean())\n",
    "    train_epoch_loss = np.append( train_epoch_loss, train_batch_loss.mean())\n",
    "\n",
    "    for batch_inputs, batch_labels in tqdm(val_ds):\n",
    "\n",
    "      student_logits = student_model(batch_inputs, training=False)\n",
    "      teacher_logits = teacher_model(batch_inputs, training=False)\n",
    "\n",
    "      distillation_loss = criterian_distillation(log_softmax(teacher_logits / T, axis=-1), softmax(student_logits / T, axis=-1))\n",
    "\n",
    "      hard_target_loss = criterian(batch_labels, student_logits)\n",
    "\n",
    "      loss = alpha * hard_target_loss + (1.0 - alpha) * T ** 2 * distillation_loss\n",
    "\n",
    "      accuracy_fn.update_state(y_true=batch_labels, y_pred=student_logits)\n",
    "      val_batch_loss = np.append(val_batch_loss, loss.numpy())\n",
    "      val_batch_accuracy = np.append(val_batch_accuracy, accuracy_fn.result().numpy())\n",
    "\n",
    "    val_epoch_accuracy = np.append(val_epoch_accuracy, val_batch_accuracy.mean())\n",
    "    val_epoch_loss = np.append(val_epoch_loss, val_batch_loss.mean())\n",
    "    min_val_epoch_loss = min(val_epoch_loss)\n",
    "    \n",
    "    if min_val_epoch_loss == val_epoch_loss[epoch]:\n",
    "      print(\"Saving checkpoint\")\n",
    "      student_model.save_weights(\"./student_model/checkpoint/\")\n",
    "    \n",
    "    else:\n",
    "      print(\"Validation loss has increased hence not saving checkpoint\")\n",
    "\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_epoch_loss[epoch]}')\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}],  Train Accuracy: {train_epoch_accuracy[epoch]}\")\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_epoch_loss[epoch]}')\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}],  Validation Accuracy: {val_epoch_accuracy[epoch]}\")\n",
    "  return student_model, train_epoch_loss, train_epoch_accuracy, val_epoch_loss, val_epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc64effc3554d048dad4aac2367c7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6269a31c26fe4690abc0fc0272e41e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [1/15], Train Loss: 0.6281450319069403\n",
      "Epoch [1/15],  Train Accuracy: 0.46611725201464105\n",
      "Epoch [1/15], Validation Loss: 0.27210166051306506\n",
      "Epoch [1/15],  Validation Accuracy: 0.568781899457628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f008fdbb8b491aad49a803061bdb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da901dff0cb34c588fa96572b655e2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [2/15], Train Loss: 0.2608698692671594\n",
      "Epoch [2/15],  Train Accuracy: 0.6021511014710125\n",
      "Epoch [2/15], Validation Loss: 0.2426182274621996\n",
      "Epoch [2/15],  Validation Accuracy: 0.6262805577028882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8674a5e97de7451db609445ee419cf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc8213009154f44a048f8affb55f517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [3/15], Train Loss: 0.23684818930181004\n",
      "Epoch [3/15],  Train Accuracy: 0.6433461636219948\n",
      "Epoch [3/15], Validation Loss: 0.20630823634564877\n",
      "Epoch [3/15],  Validation Accuracy: 0.6574571979316798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ade70daeb8c4c5e95a2973f9f00d7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3286c528204c60bd3f533ad70bd9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss has increased hence not saving checkpoint\n",
      "Epoch [4/15], Train Loss: 0.2157093257009134\n",
      "Epoch [4/15],  Train Accuracy: 0.6691873211127061\n",
      "Epoch [4/15], Validation Loss: 0.21251927172257143\n",
      "Epoch [4/15],  Validation Accuracy: 0.6789951338009401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04cfedb5fc54bc5a9cbef73e9ea642c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81cc05e54c4400e89b9a9b29d0a8b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss has increased hence not saving checkpoint\n",
      "Epoch [5/15], Train Loss: 0.21405470403086427\n",
      "Epoch [5/15],  Train Accuracy: 0.686135262505621\n",
      "Epoch [5/15], Validation Loss: 0.22817758902568708\n",
      "Epoch [5/15],  Validation Accuracy: 0.6909506259994074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bbaade605048dc9e48106d9429960f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54003d7e6e8479f989c9e8201b22096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [6/15], Train Loss: 0.20443601367140768\n",
      "Epoch [6/15],  Train Accuracy: 0.695523583821082\n",
      "Epoch [6/15], Validation Loss: 0.1873821628025987\n",
      "Epoch [6/15],  Validation Accuracy: 0.7006486498496749\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e50c74cd164d95907ddeedb35d1ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f3f6e7437c4aa197f22bb9eba4ee8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [7/15], Train Loss: 0.19765021325091692\n",
      "Epoch [7/15],  Train Accuracy: 0.7058517061747037\n",
      "Epoch [7/15], Validation Loss: 0.17803616313771767\n",
      "Epoch [7/15],  Validation Accuracy: 0.7103222019293092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3ad899cadb46789a88961490cd2f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dcf2209221a4e0da4f11d821548a3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss has increased hence not saving checkpoint\n",
      "Epoch [8/15], Train Loss: 0.191572881555795\n",
      "Epoch [8/15],  Train Accuracy: 0.7149045037747788\n",
      "Epoch [8/15], Validation Loss: 0.17883622053671966\n",
      "Epoch [8/15],  Validation Accuracy: 0.7184305841272528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c36c1045a0a4914b875222d6175cb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dde365f723b4e49bfee066efc23dd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss has increased hence not saving checkpoint\n",
      "Epoch [9/15], Train Loss: 0.18668069369942375\n",
      "Epoch [9/15],  Train Accuracy: 0.7221217277722481\n",
      "Epoch [9/15], Validation Loss: 0.18652029530229894\n",
      "Epoch [9/15],  Validation Accuracy: 0.7251135571436449\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e560998b823f48a5aea53fda77a42acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a574ca7fbcf43238eadd465280cc27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss has increased hence not saving checkpoint\n",
      "Epoch [10/15], Train Loss: 0.1795806909813161\n",
      "Epoch [10/15],  Train Accuracy: 0.7286388204987572\n",
      "Epoch [10/15], Validation Loss: 0.18889242122796449\n",
      "Epoch [10/15],  Validation Accuracy: 0.7310115241191604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce23e6967774d1b85915dd4d8585e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a4c3a96eb34496b28c422a56ddab56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [11/15], Train Loss: 0.17631927240862805\n",
      "Epoch [11/15],  Train Accuracy: 0.7335941881535739\n",
      "Epoch [11/15], Validation Loss: 0.17554659362543712\n",
      "Epoch [11/15],  Validation Accuracy: 0.7361338626254689\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670c9f1a91fe4c8da8c914de1323169f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc71bd3b36d3420ea91ad822c7d7af0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [12/15], Train Loss: 0.1747839253427636\n",
      "Epoch [12/15],  Train Accuracy: 0.738684838314002\n",
      "Epoch [12/15], Validation Loss: 0.17361309760334817\n",
      "Epoch [12/15],  Validation Accuracy: 0.7409396300261671\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836b36583b504093be61af735b6c936b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278ed23156e241699380654dbefd1ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [13/15], Train Loss: 0.1702711629307168\n",
      "Epoch [13/15],  Train Accuracy: 0.7432975718098828\n",
      "Epoch [13/15], Validation Loss: 0.17024040954526176\n",
      "Epoch [13/15],  Validation Accuracy: 0.7451205714182421\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd87fbb717344c69c3ec037c3befc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76ca7677b9e440398b675af70f8a814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [14/15], Train Loss: 0.16575277311212658\n",
      "Epoch [14/15],  Train Accuracy: 0.7473923733771017\n",
      "Epoch [14/15], Validation Loss: 0.16108575238930908\n",
      "Epoch [14/15],  Validation Accuracy: 0.7494508759541945\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d4f112214f412abf5b568287b656b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2ea1dfb24849cab43ec5304199be96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint\n",
      "Epoch [15/15], Train Loss: 0.16436281963715865\n",
      "Epoch [15/15],  Train Accuracy: 0.7515055353824909\n",
      "Epoch [15/15], Validation Loss: 0.15170756621624937\n",
      "Epoch [15/15],  Validation Accuracy: 0.7532578435811129\n"
     ]
    }
   ],
   "source": [
    "student_model, train_loss, train_accuracy, val_loss, val_accuracy = train_student_model(model, student_model, preprocess_train_ds, preprocess_val_ds, num_epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./student_model.pkl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./student_model.pkl/assets\n"
     ]
    }
   ],
   "source": [
    "student_model.save(\"./student_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 10:46:00.164406: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open ./student_model.pkl: FAILED_PRECONDITION: student_model.pkl; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x128033250>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.load_weights(\"./student_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_fn = keras.metrics.SparseCategoricalAccuracy()\n",
    "test_acc = np.array([])\n",
    "for batch_input, batch_label in preprocess_test_ds:\n",
    "    student_test_logits = student_model(batch_input, training=False)\n",
    "    acc_fn.update_state(batch_label, student_test_logits)\n",
    "    batch_acc = acc_fn.result().numpy()\n",
    "    test_acc = np.append(test_acc, batch_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8063186927044645"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
