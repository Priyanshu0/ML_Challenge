{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-NuSubx-5lpC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE_F737f6-HY",
        "outputId": "8ff1bef3-9d1b-41a9-eb86-36dfe725d701"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_filepath = \"/content/drive/MyDrive/klimb_llm_optimization_challenge.zip\""
      ],
      "metadata": {
        "id": "GDmRWhmE8ZWu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_path = \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "dXIhKREK7n8T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_to_extract = \"klimb_llm_optimization_challenge/seg_train\""
      ],
      "metadata": {
        "id": "OOz3gWKu83J5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file_to_extract = \"klimb_llm_optimization_challenge/seg_test/\""
      ],
      "metadata": {
        "id": "yRhSe_4GAnsM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.isfile(zip_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i20T8tVY98sW",
        "outputId": "28f40785-04e7-457a-971b-e70538f110bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(zip_filepath, \"r\") as zip_ref:\n",
        "  if not zip_ref.namelist():\n",
        "    print(\"No items found in archive\")\n",
        "  else:\n",
        "    for item in zip_ref.namelist():\n",
        "      zip_ref.extract(item, extract_path)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "hcJVwjR487yn",
        "outputId": "7d4883ab-8119-4d3a-d04f-8acc56fd946c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-246f490e7077>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, pwd)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1700\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mfdst_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;34m\"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Localize variable access to minimize overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path of train and test data\n",
        "train_dir = \"/content/drive/MyDrive/klimb_llm_optimization_challenge/seg_train/\"\n",
        "test_dir = \"/content/drive/MyDrive/klimb_llm_optimization_challenge/seg_test/\""
      ],
      "metadata": {
        "id": "jWk-q2IhAtR3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data configs\n",
        "batch_size = 32\n",
        "img_height = 150\n",
        "img_width = 150\n",
        "seed = 123"
      ],
      "metadata": {
        "id": "g8NxJzP5A3e2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train data\n",
        "train_ds, validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "train_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"both\",\n",
        "  seed=seed,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij-i-rSSA6Qo",
        "outputId": "9d0993fa-b7b3-4b73-d413-601ff29d30d7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 11228 files for training.\n",
            "Using 2806 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZMmg3vvLua_",
        "outputId": "6f566934-35db-471d-8ba1-f193c3c11b89"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  seed=seed,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA3nQC47A87D",
        "outputId": "028814c1-bb1a-4f70-b102-0e2fc6683844"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3000 files belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the MASTER Model - using Transfer Learning\n",
        "# Here we are using ImageNet pre-trained model weights\n",
        "base_model = keras.applications.ResNet152(\n",
        "\t\tweights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "\t\tinput_shape=(img_height, img_width, 3),\n",
        "\t\tinclude_top=False)  # Do not include the ImageNet classifier at the top.\n",
        "base_model.trainable = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DktMw9OaCnCp",
        "outputId": "a79627d2-977f-4afa-976c-ba3c0a1865e8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234698864/234698864 [==============================] - 11s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(img_height, img_width, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning.\n",
        "x = base_model(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(6)(x)\n",
        "teacher_model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "14Ldlo1qCqPo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_model.summary()\n",
        "teacher_model.compile(\n",
        "\t\toptimizer=keras.optimizers.legacy.Adam(learning_rate=0.001),\n",
        "\t\tloss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "\t\tmetrics=[keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnpYmfOmCuOm",
        "outputId": "9c066a13-803d-4031-e61f-b6f675670f89"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " resnet152 (Functional)      (None, 5, 5, 2048)        58370944  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 12294     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58383238 (222.71 MB)\n",
            "Trainable params: 12294 (48.02 KB)\n",
            "Non-trainable params: 58370944 (222.67 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "teacher_model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nZczDn_CwUA",
        "outputId": "6f24a815-4abd-45b9-d8c3-67e222c9bc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 71/351 [=====>........................] - ETA: 43:53 - loss: 0.6577 - sparse_categorical_accuracy: 0.7685"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate results on test data\n",
        "results = teacher_model.evaluate(test_ds)\n",
        "print(f\"Test accuracy with trained teacher model:{results[1]*100 :.2f} %\")"
      ],
      "metadata": {
        "id": "b3fnRok4C0F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.nn import softmax"
      ],
      "metadata": {
        "id": "W8YNdcHLKUHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_labels_train = softmax(teacher_model.predict(train_ds), axis=-1)"
      ],
      "metadata": {
        "id": "YxBMSFo9Ktuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_labels_train.shape"
      ],
      "metadata": {
        "id": "bdhJexkVK-r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_labels_val = softmax(teacher_model.predict(validation_ds), axis=-1)"
      ],
      "metadata": {
        "id": "QIieWoDAU0-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_student_model(input_shape, num_classes):\n",
        "  model = keras.models.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2DTranspose(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape, strides=(1,1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2), padding='valid', strides=(1,1)))\n",
        "  model.add(layers.Conv2D(64, kernel_size= (5, 5), activation='relu', strides=(1,1)))\n",
        "  model.add(layers.MaxPooling2D((4,4), padding='valid', strides=(1,1)))\n",
        "  model.add(layers.GlobalAveragePooling2D())\n",
        "  model.add(layers.Dense(6))\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "lDvvyWCxFjyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model = create_student_model((img_height, img_width, 3), 6)"
      ],
      "metadata": {
        "id": "9dxvd6zmHMXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_model.summary()"
      ],
      "metadata": {
        "id": "eWCEKmQdHkyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_categorical_accuracy = keras.metrics.SparseCategoricalAccuracy()"
      ],
      "metadata": {
        "id": "OD2ZvmfAZwME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_student_model(teacher_model, student_model, train_loader, soft_labels, num_epochs=50, learning_rate=0.001):\n",
        "  optimizer=keras.optimizers.legacy.Adam(learning_rate=learning_rate)\n",
        "  loss_fn =keras.losses.KLDivergence()\n",
        "  epoch_loss = np.array([])\n",
        "  epoch_accuracy = np.array([])\n",
        "  for epoch in range(num_epochs):\n",
        "    batch_loss = np.array([])\n",
        "    batch_accuracy = np.array([])\n",
        "    for inputs, _ in train_loader:\n",
        "      with tf.GradientTape() as tape:\n",
        "\n",
        "        student_predictions = student_model(inputs, training=True)\n",
        "        loss = loss_fn(softmax(teacher_model(inputs, training=False), axis=-1), softmax(student_predictions, axis=-1))\n",
        "        accuracy = sparse_categorical_accuracy.update_state(y_true=softmax(teacher_model(inputs, training=False), axis=-1).numpy(), y_pred=softmax(student_predictions, axis=-1).numpy())\n",
        "        batch_loss.append(loss.numpy())\n",
        "        batch_accuracy.append(accuracy.numpy())\n",
        "\n",
        "      gradients = tape.gradient(loss, student_model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(gradients, student_model.trainable_variables))\n",
        "    epoch_accuracy.append(batch_accuracy.mean())\n",
        "    epoch_loss.append(batch_loss.mean())\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss[epoch]}')\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Accuracy: {epoch_accuracy[epoch]}\")"
      ],
      "metadata": {
        "id": "KHh3VwFSIeCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_student_model(teacher_model, student_model, train_ds, soft_labels_train)"
      ],
      "metadata": {
        "id": "-wYcrlBJRMtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pUnVxE8BRTHl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}